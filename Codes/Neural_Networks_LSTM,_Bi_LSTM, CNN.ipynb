{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ge-Fp-rZTbT"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOzFsp3dYy17",
        "outputId": "72a3af61-8fca-42f5-bdcd-a087c797cceb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-08-06 18:12:33--  http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]\n",
            "--2022-08-06 18:12:33--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n",
            "--2022-08-06 18:12:33--  https://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408563 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip’\n",
            "\n",
            "glove.twitter.27B.z 100%[===================>]   1.42G  4.99MB/s    in 4m 45s  \n",
            "\n",
            "2022-08-06 18:17:17 (5.09 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
            "\n",
            "--2022-08-06 18:17:18--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-08-06 18:17:18--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-08-06 18:17:18--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2022-08-06 18:19:57 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.twitter.27B.zip\n",
            "  inflating: data/glove_twitter/glove.twitter.27B.25d.txt  \n",
            "  inflating: data/glove_twitter/glove.twitter.27B.50d.txt  \n",
            "  inflating: data/glove_twitter/glove.twitter.27B.100d.txt  \n",
            "  inflating: data/glove_twitter/glove.twitter.27B.200d.txt  \n",
            "Archive:  glove.6B.zip\n",
            "  inflating: data/glove/glove.6B.50d.txt  \n",
            "  inflating: data/glove/glove.6B.100d.txt  \n",
            "  inflating: data/glove/glove.6B.200d.txt  \n",
            "  inflating: data/glove/glove.6B.300d.txt  \n"
          ]
        }
      ],
      "source": [
        "!mkdir data\n",
        "!mkdir data/glove\n",
        "!mkdir data/glove_twitter\n",
        "!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "\n",
        "!unzip glove.twitter.27B.zip -d data/glove_twitter/\n",
        "!unzip glove.6B.zip -d data/glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2luDL_RZWAv",
        "outputId": "4e52b052-21df-4641-8d14-bca9c07132f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-08-06 18:20:59--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  52.7MB/s    in 13s     \n",
            "\n",
            "2022-08-06 18:21:13 (50.3 MB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
            "\n",
            "Archive:  wiki-news-300d-1M.vec.zip\n",
            "  inflating: data/wiki-news-vec/wiki-news-300d-1M.vec  \n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "!unzip wiki-news-300d-1M.vec.zip -d data/wiki-news-vec/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "QpWBbkcJ-SN1"
      },
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd, csv, tensorflow as tf, gensim as gensim\n",
        "from collections import Counter\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models import KeyedVectors\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, LSTM, Embedding, Dropout, BatchNormalization, Activation, Bidirectional, Flatten\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "oNrHKBTqlAxm"
      },
      "outputs": [],
      "source": [
        "def read_data(path1, path2):\n",
        "  train = pd.read_csv(path1)\n",
        "  test = pd.read_csv(path2)\n",
        "  print(\"Train Shape\" + str(train.shape))\n",
        "  print(\"Test Shape\" + str(test.shape))\n",
        "  return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "hVhtMb7Bne4S"
      },
      "outputs": [],
      "source": [
        "#separate the text data based on the space\n",
        "def sequentialize_data(train, test):\n",
        "  train_head_seq = [text_to_word_sequence(head) for head in train['Headline']]\n",
        "  train_body_seq = [text_to_word_sequence(body) for body in train['articleBody']]\n",
        "  test_head_seq = [text_to_word_sequence(head) for head in test['Headline']]\n",
        "  test_body_seq = [text_to_word_sequence(body) for body in test['articleBody']]\n",
        "  print(\"Train head sequence \" +str(len(train_head_seq)))\n",
        "  print(\"Train body sequence \" +str(len(train_body_seq)))\n",
        "  print(\"Test head sequence \" +str(len(test_head_seq)))\n",
        "  print(\"Test body sequence \" +str(len(test_body_seq)))\n",
        "  return (train_head_seq, train_body_seq, test_head_seq, test_body_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9YLJptcXvuIq"
      },
      "outputs": [],
      "source": [
        "def concatenate_train_data(train_head_seq, train_body_seq):\n",
        "  words = []\n",
        "  for i in range(len(train_head_seq)):    \n",
        "      words.append(train_head_seq[i])\n",
        "  print(\"Length of words after adding Headlines\" + str(len(words)))\n",
        "  print(words[:250])\n",
        "  for i in range(len(train_body_seq)):\n",
        "    words.append(train_body_seq[i])\n",
        "  print(\"Length of words after adding Headlines\" + str(len(words)))\n",
        "  print(words[250:500])\n",
        "  return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "3EyMtIQMYBjp"
      },
      "outputs": [],
      "source": [
        "# vectorize the data - the sequence that has been received has to now be converted into a set of vectors for the tensor to process.\n",
        "def vectorize_data(list):\n",
        "  symbols = '!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
        "  tokenizer = Tokenizer(num_words= 30000, filters = symbols)\n",
        "  tokenizer.fit_on_texts([word for word in words])\n",
        "  # print(\"Size of Vocabulary:\", len(tokenizer.word_index))\n",
        "  return tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "nUL9tAF6nQ_b"
      },
      "outputs": [],
      "source": [
        "def extend_data(train_head_seq, test_head_seq, train_body_seq, train, test, tokenizer):\n",
        "  train_seq = [list(i) for i in train_head_seq]\n",
        "  for i in range(len(train_head_seq)):\n",
        "      train_seq[i].extend(train_body_seq[i]) \n",
        "  test_seq = [list(i) for i in test_head_seq]\n",
        "  for i in range(len(test_head_seq)):\n",
        "      test_seq[i].extend(test_body_seq[i])\n",
        "  # print('After Sequentialization')\n",
        "  # print(\"Length of train_seq \" +str(len(train_seq)))\n",
        "  # print(\"Length of test_seq \" +str(len(test_seq)))\n",
        "  X_train = tokenizer.texts_to_sequences([' '.join(seq[:128]) for seq in train_seq])\n",
        "  X_train = pad_sequences(X_train, maxlen = 128, padding = 'post', truncating = 'post')\n",
        "  y_train = train['Stance']\n",
        "  # print('Train data After Tokenization')\n",
        "  # print(\"X_train Shape \" + str(X_train.shape))\n",
        "  # print(\"y_train Shape \" + str(y_train.shape))\n",
        "  X_test = tokenizer.texts_to_sequences([' '.join(seq[:128]) for seq in test_seq])\n",
        "  X_test = pad_sequences(X_test, maxlen = 128, padding = 'post', truncating = 'post')\n",
        "  y_test = test['Stance']\n",
        "  # print('Test data After Tokenization')\n",
        "  # print(\"X_test Shape \" + str(X_test.shape))\n",
        "  # print(\"y_test Shape \" + str(y_test.shape))\n",
        "  encoder = LabelEncoder()\n",
        "  encoder.fit(y_train)\n",
        "  train_encoded = encoder.transform(y_train)\n",
        "  y_train = to_categorical(train_encoded)\n",
        "  print('Train Data After Encoding, \\n')\n",
        "  print(\"X_train Shape \" + str(X_train.shape))\n",
        "  print(\"X_test Shape \" + str(X_test.shape))\n",
        "  print(\"y_train Shape \" + str(y_train.shape))\n",
        "  print(\"y_test Shape \" + str(y_test.shape)+'\\n')\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state = 42, test_size = 0.1)\n",
        "  encoder = LabelEncoder()\n",
        "  encoder.fit(y_test)\n",
        "  test_encoded = encoder.transform(y_test)\n",
        "  y_test = to_categorical(test_encoded)\n",
        "  print('Train Data After Encoding and splitting, \\n')\n",
        "  print(\"X_train Shape \" + str(X_train.shape))\n",
        "  print(\"X_test Shape \" + str(X_test.shape))\n",
        "  print(\"y_train Shape \" + str(y_train.shape))\n",
        "  print(\"y_test Shape \" + str(y_test.shape))\n",
        "  return X_train, y_train, X_val, y_val, X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WotYpOra5hX3",
        "outputId": "b286cec3-3278-45d8-802e-368a66e7f3a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Shape(49972, 4)\n",
            "Test Shape(25413, 4)\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "if i == 0:\n",
        "  path1 = './train.csv'\n",
        "elif i == -1: \n",
        "  path1 = './train_undersample.csv'\n",
        "elif i == 1:\n",
        "  path1 = './train_oversample.csv'\n",
        "else:\n",
        "  path1 = './train.csv'\n",
        "train, test = read_data(path1, './test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBM6fsSv5iA0",
        "outputId": "77a4c1f9-8019-4d52-8241-bf2a23c59a18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train head sequence 49972\n",
            "Train body sequence 49972\n",
            "Test head sequence 25413\n",
            "Test body sequence 25413\n"
          ]
        }
      ],
      "source": [
        "train_head_seq, train_body_seq, test_head_seq, test_body_seq = sequentialize_data(train, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUQ6kdFG5iGl",
        "outputId": "4a39585d-436f-4ee2-ea2a-2521a6d1b6c7"
      },
      "outputs": [],
      "source": [
        "words = []\n",
        "words = concatenate_train_data(train_head_seq, train_body_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwPeZDbn5iLt",
        "outputId": "b55f8018-54fb-4dbd-db97-54de5ee486c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data After Encoding, \n",
            "\n",
            "X_train Shape (49972, 128)\n",
            "X_test Shape (25413, 128)\n",
            "y_train Shape (49972, 4)\n",
            "y_test Shape (25413,)\n",
            "\n",
            "Train Data After Encoding and splitting, \n",
            "\n",
            "X_train Shape (44974, 128)\n",
            "X_test Shape (25413, 128)\n",
            "y_train Shape (44974, 4)\n",
            "y_test Shape (25413, 4)\n"
          ]
        }
      ],
      "source": [
        "tokenizer = vectorize_data(words)\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = extend_data(train_head_seq, test_head_seq, train_body_seq, train, test, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75EfkwwL2h16",
        "outputId": "fc7ab65e-3879-4137-91d8-b022bd9c2944"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44974\n",
            "44974\n"
          ]
        }
      ],
      "source": [
        "print(len(X_train))\n",
        "print(len(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "JRH--9sn_Bg2"
      },
      "outputs": [],
      "source": [
        "glove_input_file = './data/glove_twitter/glove.twitter.27B.50d.txt'\n",
        "word2vec_output_file = 'glove.50d.txt.word2vec'\n",
        "glove2word2vec(glove_input_file, word2vec_output_file)\n",
        "embeddings = gensim.models.KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "XRpo7_c3_BkT"
      },
      "outputs": [],
      "source": [
        "weight_matrix = np.random.uniform(-0.05, 0.05, size=(len(tokenizer.word_index)+1, 50)) \n",
        "for word, i in tokenizer.word_index.items():\n",
        "    try:\n",
        "        word_embeddings_vector = embeddings[word]\n",
        "    except KeyError:\n",
        "        word_embeddings_vector = None\n",
        "    if word_embeddings_vector is not None:\n",
        "        weight_matrix[i] = word_embeddings_vector\n",
        "del embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "aHTndrIM_Bnv"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim = 50, weights = [weight_matrix], trainable = True, mask_zero=True))\n",
        "model.add(LSTM(120, return_sequences = False))\n",
        "model.add(Dropout(rate = 0.3)) \n",
        "model.add(Dense(4, activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gCx5YoV_Bqz",
        "outputId": "4c8f7b30-856c-4069-9496-3279133060d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "352/352 [==============================] - 13s 23ms/step - loss: 0.7716 - accuracy: 0.7318 - val_loss: 0.6944 - val_accuracy: 0.7661\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.6136 - accuracy: 0.7773 - val_loss: 0.5517 - val_accuracy: 0.8051\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.5189 - accuracy: 0.8100 - val_loss: 0.5043 - val_accuracy: 0.8197\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.4670 - accuracy: 0.8281 - val_loss: 0.4773 - val_accuracy: 0.8301\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.4280 - accuracy: 0.8411 - val_loss: 0.4416 - val_accuracy: 0.8407\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.3861 - accuracy: 0.8538 - val_loss: 0.4004 - val_accuracy: 0.8613\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.3480 - accuracy: 0.8676 - val_loss: 0.3915 - val_accuracy: 0.8641\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.3109 - accuracy: 0.8810 - val_loss: 0.3671 - val_accuracy: 0.8659\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.2748 - accuracy: 0.8958 - val_loss: 0.3525 - val_accuracy: 0.8749\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 7s 18ms/step - loss: 0.2493 - accuracy: 0.9055 - val_loss: 0.3266 - val_accuracy: 0.8854\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.2215 - accuracy: 0.9145 - val_loss: 0.3170 - val_accuracy: 0.8904\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.2013 - accuracy: 0.9222 - val_loss: 0.3109 - val_accuracy: 0.8938\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.1777 - accuracy: 0.9312 - val_loss: 0.3206 - val_accuracy: 0.8986\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.1646 - accuracy: 0.9374 - val_loss: 0.3166 - val_accuracy: 0.8958\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.1494 - accuracy: 0.9428 - val_loss: 0.3179 - val_accuracy: 0.9046\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.1334 - accuracy: 0.9491 - val_loss: 0.3106 - val_accuracy: 0.9060\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.1250 - accuracy: 0.9517 - val_loss: 0.3209 - val_accuracy: 0.9014\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.1170 - accuracy: 0.9552 - val_loss: 0.3214 - val_accuracy: 0.9040\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.1076 - accuracy: 0.9588 - val_loss: 0.3160 - val_accuracy: 0.9104\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.0981 - accuracy: 0.9622 - val_loss: 0.3232 - val_accuracy: 0.9122\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.0927 - accuracy: 0.9656 - val_loss: 0.3413 - val_accuracy: 0.9078\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.0889 - accuracy: 0.9658 - val_loss: 0.3242 - val_accuracy: 0.9124\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.0834 - accuracy: 0.9683 - val_loss: 0.3309 - val_accuracy: 0.9120\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.0782 - accuracy: 0.9703 - val_loss: 0.3409 - val_accuracy: 0.9106\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 0.0727 - accuracy: 0.9727 - val_loss: 0.3490 - val_accuracy: 0.9128\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, batch_size = 128, epochs = 25, validation_data = (X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "j-ckGRE0q-m-"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(X_test)\n",
        "predicted_labels = [np.argmax(p, axis = -1) for p in pred]\n",
        "True_labels = [np.argmax(p, axis = -1) for p in y_test]\n",
        "for i in range(len(predicted_labels)):\n",
        "    if predicted_labels[i] == 0: predicted_labels[i] = \"unrelated\"\n",
        "    if predicted_labels[i] == 1: predicted_labels[i] = \"agree\"\n",
        "    if predicted_labels[i] == 2: predicted_labels[i] = \"disagree\"\n",
        "    if predicted_labels[i] == 3: predicted_labels[i] = \"discuss\"\n",
        "for i in range(len(True_labels)):\n",
        "    if True_labels[i] == 0: True_labels[i] = \"unrelated\"\n",
        "    if True_labels[i] == 1: True_labels[i] = \"agree\"\n",
        "    if True_labels[i] == 2: True_labels[i] = \"disagree\"\n",
        "    if True_labels[i] == 3: True_labels[i] = \"discuss\"\n",
        "test_df = pd.read_csv('competition_test_stances.csv')\n",
        "pred_stance = predicted_labels\n",
        "bodyid = []\n",
        "headline = []\n",
        "for i in range(len(test_df.Stance)):\n",
        "    bodyid.append(test_df['Body ID'][i])\n",
        "    headline.append(test_df['Headline'][i])\n",
        "df_submit = pd.DataFrame( data = {'Headline': headline, 'Body ID': bodyid, \"Stance\": pred_stance})\n",
        "df_submit.to_csv('answer_BaseLSTM.csv', index = False, encoding = 'utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "_n_8ZR9b_BuW"
      },
      "outputs": [],
      "source": [
        "# from keras.models import save_model\n",
        "# filepath = './lstm_base_model'\n",
        "# save_model(model, filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3Tqh4zRV8hU",
        "outputId": "1fef996a-67d5-4147-cbea-b11f86b759d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    256    |    22     |    272    |   1353    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    52     |    12     |    85     |    548    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    281    |    28     |   1417    |   2738    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |   1236    |    64     |   3231    |   13818   |\n",
            "-------------------------------------------------------------\n",
            "Score: 5324.5 out of 11651.25\t(45.6989593391267%)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "45.6989593391267"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from score import report_score, score_submission\n",
        "predicted = df_submit['Stance'].values\n",
        "actual = test_df['Stance'].values\n",
        "report_score(actual, predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "bRDJdgim_Bxn"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim = 50, weights = [weight_matrix], trainable = True, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(120, return_sequences = False)))\n",
        "model.add(Dropout(rate = 0.3)) \n",
        "model.add(Dense(4, activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHC6mQJ8_B0_",
        "outputId": "9832dd1f-8164-434c-bb23-7d2c6e87c24c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "352/352 [==============================] - 23s 43ms/step - loss: 0.6962 - accuracy: 0.7489 - val_loss: 0.5660 - val_accuracy: 0.7893\n",
            "Epoch 2/20\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.4745 - accuracy: 0.8181 - val_loss: 0.4054 - val_accuracy: 0.8435\n",
            "Epoch 3/20\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.3381 - accuracy: 0.8689 - val_loss: 0.3180 - val_accuracy: 0.8760\n",
            "Epoch 4/20\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.2527 - accuracy: 0.9034 - val_loss: 0.2685 - val_accuracy: 0.8986\n",
            "Epoch 5/20\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.1907 - accuracy: 0.9265 - val_loss: 0.2223 - val_accuracy: 0.9146\n",
            "Epoch 6/20\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 0.1513 - accuracy: 0.9438 - val_loss: 0.2076 - val_accuracy: 0.9266\n",
            "Epoch 7/20\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.1195 - accuracy: 0.9559 - val_loss: 0.1951 - val_accuracy: 0.9304\n",
            "Epoch 8/20\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 0.0969 - accuracy: 0.9639 - val_loss: 0.1979 - val_accuracy: 0.9348\n",
            "Epoch 9/20\n",
            "352/352 [==============================] - 12s 33ms/step - loss: 0.0816 - accuracy: 0.9699 - val_loss: 0.1885 - val_accuracy: 0.9396\n",
            "Epoch 10/20\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.0655 - accuracy: 0.9770 - val_loss: 0.1816 - val_accuracy: 0.9446\n",
            "Epoch 11/20\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.0563 - accuracy: 0.9800 - val_loss: 0.1935 - val_accuracy: 0.9392\n",
            "Epoch 12/20\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.0496 - accuracy: 0.9825 - val_loss: 0.1839 - val_accuracy: 0.9486\n",
            "Epoch 13/20\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.0423 - accuracy: 0.9857 - val_loss: 0.1972 - val_accuracy: 0.9440\n",
            "Epoch 14/20\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.0403 - accuracy: 0.9861 - val_loss: 0.2076 - val_accuracy: 0.9466\n",
            "Epoch 15/20\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.0333 - accuracy: 0.9889 - val_loss: 0.2057 - val_accuracy: 0.9442\n",
            "Epoch 16/20\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.0311 - accuracy: 0.9898 - val_loss: 0.1994 - val_accuracy: 0.9522\n",
            "Epoch 17/20\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.0260 - accuracy: 0.9911 - val_loss: 0.1940 - val_accuracy: 0.9520\n",
            "Epoch 18/20\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.0246 - accuracy: 0.9920 - val_loss: 0.1919 - val_accuracy: 0.9524\n",
            "Epoch 19/20\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.2234 - val_accuracy: 0.9486\n",
            "Epoch 20/20\n",
            "352/352 [==============================] - 11s 32ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 0.2241 - val_accuracy: 0.9472\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, batch_size = 128, epochs = 20, validation_data = (X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "jBDh7OgErkKs"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(X_test)\n",
        "predicted_labels = [np.argmax(p, axis = -1) for p in pred]\n",
        "True_labels = [np.argmax(p, axis = -1) for p in y_test]\n",
        "for i in range(len(predicted_labels)):\n",
        "    if predicted_labels[i] == 0: predicted_labels[i] = \"unrelated\"\n",
        "    if predicted_labels[i] == 1: predicted_labels[i] = \"agree\"\n",
        "    if predicted_labels[i] == 2: predicted_labels[i] = \"disagree\"\n",
        "    if predicted_labels[i] == 3: predicted_labels[i] = \"discuss\"\n",
        "for i in range(len(True_labels)):\n",
        "    if True_labels[i] == 0: True_labels[i] = \"unrelated\"\n",
        "    if True_labels[i] == 1: True_labels[i] = \"agree\"\n",
        "    if True_labels[i] == 2: True_labels[i] = \"disagree\"\n",
        "    if True_labels[i] == 3: True_labels[i] = \"discuss\"\n",
        "test_df = pd.read_csv('competition_test_stances.csv')\n",
        "pred_stance = predicted_labels\n",
        "bodyid = []\n",
        "headline = []\n",
        "for i in range(len(test_df.Stance)):\n",
        "    bodyid.append(test_df['Body ID'][i])\n",
        "    headline.append(test_df['Headline'][i])\n",
        "df_submit = pd.DataFrame( data = {'Headline': headline, 'Body ID': bodyid, \"Stance\": pred_stance})\n",
        "df_submit.to_csv('answer_BiLSTM.csv', index = False, encoding = 'utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i4cvM9G_B3-",
        "outputId": "aebd116a-535c-4d38-9626-922ba86bdcc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    517    |    16     |    389    |    981    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    139    |    20     |    135    |    403    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    574    |    43     |   1883    |   1964    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |   1086    |    56     |   1788    |   15419   |\n",
            "-------------------------------------------------------------\n",
            "Score: 6598.75 out of 11651.25\t(56.635554125093876%)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "56.635554125093876"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted = df_submit['Stance'].values\n",
        "actual = test_df['Stance'].values\n",
        "report_score(actual, predicted)\n",
        "# filepath = './lstm_bidirectional_model'\n",
        "# save_model(model, filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "8dqjFKHX_B7L"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim = len(tokenizer.word_index)+1, output_dim = 50, weights = [weight_matrix], trainable = True, input_length = 128))\n",
        "model.add(Conv1D(512, 3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Conv1D(128, 3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Conv1D(64, 3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dropout(rate = 0.25))\n",
        "model.add(Dense(4,activation ='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIBpco16_B-f",
        "outputId": "e4152b83-18c9-4c95-c17f-aae6dbe553e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "352/352 [==============================] - 5s 11ms/step - loss: 0.6923 - accuracy: 0.7491 - val_loss: 0.5057 - val_accuracy: 0.8125\n",
            "Epoch 2/20\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.4039 - accuracy: 0.8441 - val_loss: 0.3437 - val_accuracy: 0.8729\n",
            "Epoch 3/20\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.2701 - accuracy: 0.8985 - val_loss: 0.2601 - val_accuracy: 0.9038\n",
            "Epoch 4/20\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.1993 - accuracy: 0.9259 - val_loss: 0.2186 - val_accuracy: 0.9206\n",
            "Epoch 5/20\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.1512 - accuracy: 0.9437 - val_loss: 0.1945 - val_accuracy: 0.9326\n",
            "Epoch 6/20\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.1186 - accuracy: 0.9555 - val_loss: 0.1999 - val_accuracy: 0.9334\n",
            "Epoch 7/20\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0992 - accuracy: 0.9626 - val_loss: 0.2174 - val_accuracy: 0.9350\n",
            "Epoch 8/20\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0840 - accuracy: 0.9695 - val_loss: 0.2056 - val_accuracy: 0.9400\n",
            "Epoch 9/20\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0739 - accuracy: 0.9721 - val_loss: 0.2157 - val_accuracy: 0.9374\n",
            "Epoch 10/20\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0646 - accuracy: 0.9761 - val_loss: 0.2114 - val_accuracy: 0.9384\n",
            "Epoch 11/20\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0586 - accuracy: 0.9787 - val_loss: 0.2325 - val_accuracy: 0.9422\n",
            "Epoch 12/20\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0520 - accuracy: 0.9810 - val_loss: 0.2415 - val_accuracy: 0.9410\n",
            "Epoch 13/20\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0488 - accuracy: 0.9818 - val_loss: 0.2393 - val_accuracy: 0.9448\n",
            "Epoch 14/20\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0464 - accuracy: 0.9836 - val_loss: 0.2599 - val_accuracy: 0.9410\n",
            "Epoch 15/20\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0476 - accuracy: 0.9843 - val_loss: 0.2610 - val_accuracy: 0.9426\n",
            "Epoch 16/20\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0383 - accuracy: 0.9866 - val_loss: 0.2523 - val_accuracy: 0.9492\n",
            "Epoch 17/20\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0387 - accuracy: 0.9871 - val_loss: 0.2708 - val_accuracy: 0.9508\n",
            "Epoch 18/20\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 0.0328 - accuracy: 0.9886 - val_loss: 0.2796 - val_accuracy: 0.9502\n",
            "Epoch 19/20\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0386 - accuracy: 0.9870 - val_loss: 0.2993 - val_accuracy: 0.9462\n",
            "Epoch 20/20\n",
            "352/352 [==============================] - 4s 10ms/step - loss: 0.0322 - accuracy: 0.9893 - val_loss: 0.2819 - val_accuracy: 0.9492\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, batch_size = 128, epochs = 20, validation_data = (X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "TOO_WE9-r0fF"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(X_test)\n",
        "predicted_labels = [np.argmax(p, axis = -1) for p in pred]\n",
        "True_labels = [np.argmax(p, axis = -1) for p in y_test]\n",
        "for i in range(len(predicted_labels)):\n",
        "    if predicted_labels[i] == 0: predicted_labels[i] = \"unrelated\"\n",
        "    if predicted_labels[i] == 1: predicted_labels[i] = \"agree\"\n",
        "    if predicted_labels[i] == 2: predicted_labels[i] = \"disagree\"\n",
        "    if predicted_labels[i] == 3: predicted_labels[i] = \"discuss\"\n",
        "for i in range(len(True_labels)):\n",
        "    if True_labels[i] == 0: True_labels[i] = \"unrelated\"\n",
        "    if True_labels[i] == 1: True_labels[i] = \"agree\"\n",
        "    if True_labels[i] == 2: True_labels[i] = \"disagree\"\n",
        "    if True_labels[i] == 3: True_labels[i] = \"discuss\"\n",
        "test_df = pd.read_csv('competition_test_stances.csv')\n",
        "pred_stance = predicted_labels\n",
        "bodyid = []\n",
        "headline = []\n",
        "for i in range(len(test_df.Stance)):\n",
        "    bodyid.append(test_df['Body ID'][i])\n",
        "    headline.append(test_df['Headline'][i])\n",
        "df_submit = pd.DataFrame( data = {'Headline': headline, 'Body ID': bodyid, \"Stance\": pred_stance})\n",
        "df_submit.to_csv('answer_cnn.csv', index = False, encoding = 'utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nRFkHN0_CBf",
        "outputId": "1700e96d-51fe-4b78-9335-57a274c72dfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    416    |    44     |    496    |    947    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    149    |    10     |    130    |    408    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    588    |    38     |   2099    |   1739    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |   1144    |    127    |   2181    |   14897   |\n",
            "-------------------------------------------------------------\n",
            "Score: 6610.5 out of 11651.25\t(56.73640167364017%)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "56.73640167364017"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted = df_submit['Stance'].values\n",
        "actual = test_df['Stance'].values\n",
        "report_score(actual, predicted)\n",
        "# filepath = './cnn_model'\n",
        "# save_model(model, filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "0OxQqjHB_CEv"
      },
      "outputs": [],
      "source": [
        "word_embeddings = gensim.models.KeyedVectors.load_word2vec_format('data/wiki-news-vec/wiki-news-300d-1M.vec', binary=False)\n",
        "weight_matrix = np.random.uniform(-0.05, 0.05, size=(len(tokenizer.word_index)+1, 300)) \n",
        "for word, i in tokenizer.word_index.items(): \n",
        "    try:\n",
        "        word_embeddings_vector = word_embeddings[word]\n",
        "    except KeyError:\n",
        "        word_embeddings_vector = None\n",
        "    if word_embeddings_vector is not None:\n",
        "        weight_matrix[i] = word_embeddings_vector            \n",
        "del word_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "I0j11jso_CH_"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim = len(tokenizer.word_index)+1, output_dim = 300, weights = [weight_matrix], trainable = True, input_length = 128))\n",
        "model.add(Conv1D(256, 3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Conv1D(128, 3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Conv1D(64, 3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dropout(rate = 0.25))\n",
        "model.add(Dense(4,activation ='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l40OC9aj_CLL",
        "outputId": "e6f81e80-334f-47eb-97de-f0fe6cbae9de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "352/352 [==============================] - 6s 16ms/step - loss: 0.6224 - accuracy: 0.7690 - val_loss: 0.4136 - val_accuracy: 0.8435\n",
            "Epoch 2/20\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.3194 - accuracy: 0.8780 - val_loss: 0.2531 - val_accuracy: 0.9032\n",
            "Epoch 3/20\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1995 - accuracy: 0.9223 - val_loss: 0.1936 - val_accuracy: 0.9262\n",
            "Epoch 4/20\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1489 - accuracy: 0.9432 - val_loss: 0.1937 - val_accuracy: 0.9298\n",
            "Epoch 5/20\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.1213 - accuracy: 0.9538 - val_loss: 0.1885 - val_accuracy: 0.9350\n",
            "Epoch 6/20\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0969 - accuracy: 0.9633 - val_loss: 0.1684 - val_accuracy: 0.9444\n",
            "Epoch 7/20\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0862 - accuracy: 0.9683 - val_loss: 0.1834 - val_accuracy: 0.9458\n",
            "Epoch 8/20\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0715 - accuracy: 0.9738 - val_loss: 0.1977 - val_accuracy: 0.9454\n",
            "Epoch 9/20\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0668 - accuracy: 0.9754 - val_loss: 0.1743 - val_accuracy: 0.9500\n",
            "Epoch 10/20\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0563 - accuracy: 0.9797 - val_loss: 0.2008 - val_accuracy: 0.9498\n",
            "Epoch 11/20\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0510 - accuracy: 0.9822 - val_loss: 0.2161 - val_accuracy: 0.9514\n",
            "Epoch 12/20\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0502 - accuracy: 0.9826 - val_loss: 0.1905 - val_accuracy: 0.9542\n",
            "Epoch 13/20\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0503 - accuracy: 0.9820 - val_loss: 0.2155 - val_accuracy: 0.9514\n",
            "Epoch 14/20\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0388 - accuracy: 0.9867 - val_loss: 0.2163 - val_accuracy: 0.9550\n",
            "Epoch 15/20\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0390 - accuracy: 0.9868 - val_loss: 0.2156 - val_accuracy: 0.9538\n",
            "Epoch 16/20\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0314 - accuracy: 0.9896 - val_loss: 0.2211 - val_accuracy: 0.9558\n",
            "Epoch 17/20\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0403 - accuracy: 0.9876 - val_loss: 0.2497 - val_accuracy: 0.9538\n",
            "Epoch 18/20\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0319 - accuracy: 0.9898 - val_loss: 0.2480 - val_accuracy: 0.9522\n",
            "Epoch 19/20\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0299 - accuracy: 0.9907 - val_loss: 0.2226 - val_accuracy: 0.9564\n",
            "Epoch 20/20\n",
            "352/352 [==============================] - 5s 15ms/step - loss: 0.0289 - accuracy: 0.9905 - val_loss: 0.2265 - val_accuracy: 0.9576\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, batch_size = 128, epochs = 20, validation_data = (X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "gjncM3fsr68i"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(X_test)\n",
        "predicted_labels = [np.argmax(p, axis = -1) for p in pred]\n",
        "True_labels = [np.argmax(p, axis = -1) for p in y_test]\n",
        "for i in range(len(predicted_labels)):\n",
        "    if predicted_labels[i] == 0: predicted_labels[i] = \"unrelated\"\n",
        "    if predicted_labels[i] == 1: predicted_labels[i] = \"agree\"\n",
        "    if predicted_labels[i] == 2: predicted_labels[i] = \"disagree\"\n",
        "    if predicted_labels[i] == 3: predicted_labels[i] = \"discuss\"\n",
        "for i in range(len(True_labels)):\n",
        "    if True_labels[i] == 0: True_labels[i] = \"unrelated\"\n",
        "    if True_labels[i] == 1: True_labels[i] = \"agree\"\n",
        "    if True_labels[i] == 2: True_labels[i] = \"disagree\"\n",
        "    if True_labels[i] == 3: True_labels[i] = \"discuss\"\n",
        "test_df = pd.read_csv('competition_test_stances.csv')\n",
        "pred_stance = predicted_labels\n",
        "bodyid = []\n",
        "headline = []\n",
        "for i in range(len(test_df.Stance)):\n",
        "    bodyid.append(test_df['Body ID'][i])\n",
        "    headline.append(test_df['Headline'][i])\n",
        "df_submit = pd.DataFrame( data = {'Headline': headline, 'Body ID': bodyid, \"Stance\": pred_stance})\n",
        "df_submit.to_csv('answer_cnn_fastrack.csv', index = False, encoding = 'utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIop3VTf_COW",
        "outputId": "d3fcb598-52aa-42e4-e4a8-e9c32fafca25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    549    |    20     |    457    |    877    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    213    |    11     |    117    |    356    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    789    |    32     |   1722    |   1921    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |   1739    |    115    |   2358    |   14137   |\n",
            "-------------------------------------------------------------\n",
            "Score: 6223.25 out of 11651.25\t(53.41272395665701%)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "53.41272395665701"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted = df_submit['Stance'].values\n",
        "actual = test_df['Stance'].values\n",
        "report_score(actual, predicted)\n",
        "# filepath = './cnn_fastext_model'\n",
        "# save_model(model, filepath)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Neural Networks - LSTM, Bi LSTM, CNN.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
